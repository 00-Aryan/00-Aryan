{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9WD6L1/eTk5CGphjMQwNN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/00-Aryan/00-Aryan/blob/main/physcian_notetaker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Physician Note-taker - **medical transcription, NLP-based summarization, and sentiment analysis**."
      ],
      "metadata": {
        "id": "e4uXKpi9Vl3e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Note will be categorized in 10 section**\n",
        "\n",
        "1. Setup & Import\n",
        "2. Input and Transcript\n",
        "3. Conversation parsing\n",
        "3. Clinical Entity Extraction **(NER)**\n",
        "4. Negation Detection & Assertion Handling\n",
        "4. Clinical Logic and Normalisation\n",
        "5. Sentiment and Intent Analysis\n",
        "6. Medical Summary Generation\n",
        "7. SOAP note generation\n"
      ],
      "metadata": {
        "id": "uKHNxNnyXMAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setup & Import"
      ],
      "metadata": {
        "id": "R8Ig1LA4YysE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scispacy==0.6.2\n",
        "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_md-0.5.4.tar.gz\n",
        "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_ner_bc5cdr_md-0.5.4.tar.gz\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from spacy.matcher import Matcher\n",
        "import re\n",
        "\n",
        "from transformers import pipeline\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "en_ner_bc5cdr_md = spacy.load(\"en_ner_bc5cdr_md\")\n",
        "en_core_sci_md = spacy.load(\"en_core_sci_md\")\n",
        "\n",
        "rs = 42\n",
        "np.random.seed(rs)\n",
        "random.seed(rs)\n",
        "\n",
        "print(\"Setup & Imports complete.\")"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9Ov9vX_lock",
        "outputId": "aa43c69d-bfc9-469b-d46c-63c4634e53e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scispacy==0.6.2 in /usr/local/lib/python3.12/dist-packages (0.6.2)\n",
            "Requirement already satisfied: spacy<3.9.0,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from scispacy==0.6.2) (3.7.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from scispacy==0.6.2) (1.16.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from scispacy==0.6.2) (2.32.4)\n",
            "Requirement already satisfied: conllu in /usr/local/lib/python3.12/dist-packages (from scispacy==0.6.2) (6.0.0)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.12/dist-packages (from scispacy==0.6.2) (1.26.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from scispacy==0.6.2) (1.5.2)\n",
            "Requirement already satisfied: nmslib-metabrainz==2.1.3 in /usr/local/lib/python3.12/dist-packages (from scispacy==0.6.2) (2.1.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.3 in /usr/local/lib/python3.12/dist-packages (from scispacy==0.6.2) (1.6.1)\n",
            "Requirement already satisfied: pysbd in /usr/local/lib/python3.12/dist-packages (from scispacy==0.6.2) (0.3.4)\n",
            "Requirement already satisfied: pybind11>=2.2.3 in /usr/local/lib/python3.12/dist-packages (from nmslib-metabrainz==2.1.3->scispacy==0.6.2) (3.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from nmslib-metabrainz==2.1.3->scispacy==0.6.2) (5.9.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->scispacy==0.6.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->scispacy==0.6.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->scispacy==0.6.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->scispacy==0.6.2) (2025.11.12)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.20.3->scispacy==0.6.2) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (0.4.3)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (0.20.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (4.67.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (3.5.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (0.4.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.12/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (13.9.4)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (0.20.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (2.0.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.9.0,>=3.7.0->scispacy==0.6.2) (0.1.2)\n",
            "Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_md-0.5.4.tar.gz\n",
            "  Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_md-0.5.4.tar.gz (119.1 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.4 in /usr/local/lib/python3.12/dist-packages (from en_core_sci_md==0.5.4) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (0.4.3)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (0.20.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (3.5.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (1.26.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (2025.11.12)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.12/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (13.9.4)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (0.20.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (2.0.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_core_sci_md==0.5.4) (0.1.2)\n",
            "Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_ner_bc5cdr_md-0.5.4.tar.gz\n",
            "  Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_ner_bc5cdr_md-0.5.4.tar.gz (119.8 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.4 in /usr/local/lib/python3.12/dist-packages (from en_ner_bc5cdr_md==0.5.4) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (0.4.3)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (0.20.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (3.5.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (1.26.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (2025.11.12)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.12/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (13.9.4)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (0.20.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (2.0.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_ner_bc5cdr_md==0.5.4) (0.1.2)\n",
            "Setup & Imports complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Input Data or Transcript"
      ],
      "metadata": {
        "id": "G8-b9EqLjXu8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "conversation = \"\"\"\n",
        "\n",
        "\n",
        "    Physician: Good morning, Ms. Jones. How are you feeling today?\n",
        "\n",
        "    Patient: Good morning, doctor. I’m doing better, but I still have some discomfort now and then.\n",
        "\n",
        "    Physician: I understand you were in a car accident last September. Can you walk me through what happened?\n",
        "\n",
        "    Patient: Yes, it was on September 1st, around 12:30 in the afternoon. I was driving from Cheadle Hulme to Manchester when I had to stop in traffic. Out of nowhere, another car hit me from behind, which pushed my car into the one in front.\n",
        "\n",
        "    Physician: That sounds like a strong impact. Were you wearing your seatbelt?\n",
        "\n",
        "    Patient: Yes, I always do.\n",
        "\n",
        "    Physician: What did you feel immediately after the accident?\n",
        "\n",
        "    Patient: At first, I was just shocked. But then I realized I had hit my head on the steering wheel, and I could feel pain in my neck and back almost right away.\n",
        "\n",
        "    Physician: Did you seek medical attention at that time?\n",
        "\n",
        "    Patient: Yes, I went to Moss Bank Accident and Emergency. They checked me over and said it was a whiplash injury, but they didn’t do any X-rays. They just gave me some advice and sent me home.\n",
        "\n",
        "    Physician: How did things progress after that?\n",
        "\n",
        "    Patient: The first four weeks were rough. My neck and back pain were really bad—I had trouble sleeping and had to take painkillers regularly. It started improving after that, but I had to go through ten sessions of physiotherapy to help with the stiffness and discomfort.\n",
        "\n",
        "    Physician: That makes sense. Are you still experiencing pain now?\n",
        "\n",
        "    Patient: It’s not constant, but I do get occasional backaches. It’s nothing like before, though.\n",
        "\n",
        "    Physician: That’s good to hear. Have you noticed any other effects, like anxiety while driving or difficulty concentrating?\n",
        "\n",
        "    Patient: No, nothing like that. I don’t feel nervous driving, and I haven’t had any emotional issues from the accident.\n",
        "\n",
        "    Physician: And how has this impacted your daily life? Work, hobbies, anything like that?\n",
        "\n",
        "    Patient: I had to take a week off work, but after that, I was back to my usual routine. It hasn’t really stopped me from doing anything.\n",
        "\n",
        "    Physician: That’s encouraging. Let’s go ahead and do a physical examination to check your mobility and any lingering pain.\n",
        "\n",
        "    [Physical Examination Conducted]\n",
        "\n",
        "    Physician: Everything looks good. Your neck and back have a full range of movement, and there’s no tenderness or signs of lasting damage. Your muscles and spine seem to be in good condition.\n",
        "\n",
        "    Patient: That’s a relief!\n",
        "\n",
        "    Physician: Yes, your recovery so far has been quite positive. Given your progress, I’d expect you to make a full recovery within six months of the accident. There are no signs of long-term damage or degeneration.\n",
        "\n",
        "    Patient: That’s great to hear. So, I don’t need to worry about this affecting me in the future?\n",
        "\n",
        "    Physician: That’s right. I don’t foresee any long-term impact on your work or daily life. If anything changes or you experience worsening symptoms, you can always come back for a follow-up. But at this point, you’re on track for a full recovery.\n",
        "\n",
        "    Patient: Thank you, doctor. I appreciate it.\n",
        "\n",
        "    Physician: You’re very welcome, Ms. Jones. Take care, and don’t hesitate to reach out if you need anything.\"\"\""
      ],
      "metadata": {
        "id": "XxqZ4tDpZmhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Conversation Parsing"
      ],
      "metadata": {
        "id": "4THLvfsHZQB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_conversation(conversation: str) -> list[dict]:\n",
        "    dialogue = []\n",
        "\n",
        "    lines = conversation.strip().split(\"\\n\")\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        if line.startswith(\"Physician:\"):\n",
        "            speaker = \"Physician\"\n",
        "            text = line.replace(\"Physician:\", \"\", 1).strip()\n",
        "\n",
        "        elif line.startswith(\"Patient:\"):\n",
        "            speaker = \"Patient\"\n",
        "            text = line.replace(\"Patient:\", \"\", 1).strip()\n",
        "\n",
        "        else:\n",
        "\n",
        "            print(f\"Skipping unrecognized line: {line}\")\n",
        "            continue\n",
        "\n",
        "        dialogue.append({\n",
        "            \"speaker\": speaker,\n",
        "            \"text\": text\n",
        "        })\n",
        "\n",
        "    print(f\"Parsed {len(dialogue)} dialogue turns in this\")\n",
        "    return dialogue\n"
      ],
      "metadata": {
        "id": "ti5KIGKPZZ-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_dialogue = parse_conversation(conversation)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JVi4SpXJaZ8R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5a2a2e9-5799-487c-e810-7b7c914532e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping unrecognized line: [Physical Examination Conducted]\n",
            "Parsed 26 dialogue turns in this\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we have names in output trying to extract the info from our code that will not exactly match with the expected ones since we dont have {janet} in our conversation but its still better then hardcoding"
      ],
      "metadata": {
        "id": "hoHsKTCNlnLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_patient_name(dialogue: list[dict]) -> str | None:\n",
        "    \"\"\"\n",
        "    Extract patient name using honorific-based patterns.\n",
        "    Returns the most reliable form found (e.g., 'Ms. Jones').\n",
        "    \"\"\"\n",
        "\n",
        "    title_pattern = re.compile(\n",
        "        r\"\\b(Mr|Ms|Mrs|Miss)\\.\\s+([A-Z][a-z]+)\\b\"\n",
        "    )\n",
        "\n",
        "    for turn in dialogue:\n",
        "        # Physicians usually address the patient by name\n",
        "        if turn[\"speaker\"] == \"Physician\":\n",
        "            match = title_pattern.search(turn[\"text\"])\n",
        "            if match:\n",
        "                title, last_name = match.groups()\n",
        "                return f\"{title}. {last_name}\"\n",
        "\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "pvdns94Alk0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patient_name = extract_patient_name(parsed_dialogue)\n"
      ],
      "metadata": {
        "id": "U25yGE0DmGHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Clinical Entity Extraction **(NER)**\n",
        "\n"
      ],
      "metadata": {
        "id": "lrPRLE-2iyGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClinicalEntityExtractor:\n",
        "    \"\"\"\n",
        "    Module 2: Clinical Entity Extraction (NER + Rules)\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name: str = \"en_ner_bc5cdr_md\"):\n",
        "        self.nlp = spacy.load(model_name)\n",
        "        self.matcher = Matcher(self.nlp.vocab)\n",
        "        self._add_patterns()\n",
        "\n",
        "        # --- Keyword  ---\n",
        "        self.symptom_keywords = [\n",
        "            \"pain\", \"ache\", \"aches\", \"discomfort\", \"hurt\",\n",
        "            \"sore\", \"tender\", \"stiff\", \"stiffness\",\n",
        "            \"headache\", \"backache\", \"neckache\"\n",
        "        ]\n",
        "\n",
        "        self.treatment_keywords = [\n",
        "            \"physiotherapy\", \"physical therapy\", \"therapy\",\n",
        "            \"painkillers\", \"medication\", \"analgesics\",\n",
        "            \"anti-inflammatory\", \"sessions\", \"treatment\"\n",
        "        ]\n",
        "\n",
        "        self.prognosis_signals = [\n",
        "            \"recovery\", \"improving\", \"stable\",\n",
        "            \"full recovery\", \"partial recovery\"\n",
        "        ]\n",
        "\n",
        "    def _add_patterns(self):\n",
        "        # \"n no. of physiotherapy sessions\"\n",
        "        self.matcher.add(\n",
        "            \"TREATMENT_SESSION\",\n",
        "            [[{\"LIKE_NUM\": True}, {\"LOWER\": {\"IN\": [\"sessions\", \"session\"]}}]]\n",
        "        )\n",
        "\n",
        "        # \"n weeks\"\n",
        "        self.matcher.add(\n",
        "            \"DURATION\",\n",
        "            [[{\"LIKE_NUM\": True}, {\"LOWER\": {\"IN\": [\"days\", \"weeks\", \"months\", \"years\"]}}]]\n",
        "        )\n",
        "\n",
        "    def _extract_with_rules(self, text: str) -> dict:\n",
        "        extracted = defaultdict(set)\n",
        "        text_lower = text.lower()\n",
        "\n",
        "\n",
        "        for symptom in self.symptom_keywords:\n",
        "            # body-part + symptom (e.g., \"neck pain\")\n",
        "            pattern = rf\"\\b(\\w+)\\s+{symptom}\\b\"\n",
        "            for match in re.findall(pattern, text_lower):\n",
        "                if match not in {\"and\", \"the\"}:\n",
        "                    extracted[\"symptoms\"].add(f\"{match} {symptom}\")\n",
        "\n",
        "            # standalone symptom\n",
        "            if re.search(rf\"\\b{symptom}\\b\", text_lower):\n",
        "                extracted[\"symptoms\"].add(symptom)\n",
        "\n",
        "\n",
        "        for treatment in self.treatment_keywords:\n",
        "            if re.search(rf\"\\b{treatment}\\b\", text_lower):\n",
        "                extracted[\"treatments\"].add(treatment)\n",
        "\n",
        "        # --- Prognosis signals ---\n",
        "        for signal in self.prognosis_signals:\n",
        "            if signal in text_lower:\n",
        "                extracted[\"prognosis_signals\"].add(signal)\n",
        "\n",
        "\n",
        "        temporal_patterns = [\n",
        "            r\"\\b\\d+\\s+(days?|weeks?|months?|years?)\\b\",\n",
        "            r\"\\b\\d{1,2}:\\d{2}\\b\"\n",
        "        ]\n",
        "\n",
        "        for pattern in temporal_patterns:\n",
        "            for match in re.findall(pattern, text_lower):\n",
        "                extracted[\"durations\"].add(match)\n",
        "\n",
        "        return extracted\n",
        "\n",
        "\n",
        "\n",
        "    def _extract_with_ner(self, text: str, speaker: str) -> dict:\n",
        "        extracted = defaultdict(set)\n",
        "        doc = self.nlp(text)\n",
        "\n",
        "        for ent in doc.ents:\n",
        "            entity_text = ent.text.lower()\n",
        "            label = ent.label_.upper()\n",
        "\n",
        "            # en_ner_bc5cdr_md → DISEASE, CHEMICAL\n",
        "            if label == \"DISEASE\":\n",
        "              if speaker == \"Patient\":\n",
        "                  # Patient reporting a doctor's diagnosis\n",
        "                  if re.search(r\"\\b(said it was|diagnosed|told me it was|confirmed)\\b\", text.lower()):\n",
        "                      extracted[\"diagnosis\"].add(entity_text)\n",
        "                  else:\n",
        "                      extracted[\"symptoms\"].add(entity_text)\n",
        "\n",
        "              elif speaker == \"Physician\" and \"?\" not in text:\n",
        "                  extracted[\"diagnosis\"].add(entity_text)\n",
        "\n",
        "\n",
        "            elif label == \"CHEMICAL\":\n",
        "                extracted[\"treatments\"].add(entity_text)\n",
        "\n",
        "        # Matcher-based patterns (ONLY what matcher defines)\n",
        "        for match_id, start, end in self.matcher(doc):\n",
        "            span = doc[start:end]\n",
        "            rule_label = self.nlp.vocab.strings[match_id]\n",
        "\n",
        "            if rule_label == \"TREATMENT_SESSION\":\n",
        "                extracted[\"treatments\"].add(span.text.lower())\n",
        "            elif rule_label == \"DURATION\":\n",
        "                extracted[\"durations\"].add(span.text.lower())\n",
        "\n",
        "        return extracted\n",
        "\n",
        "\n",
        "    def extract_clinical_entities(self, dialogue: list[dict]) -> dict:\n",
        "        entities = {\n",
        "            \"symptoms\": set(),\n",
        "            \"diagnosis\": set(),\n",
        "            \"treatments\": set(),\n",
        "            \"prognosis_signals\": set(),\n",
        "            \"durations\": set()\n",
        "        }\n",
        "\n",
        "        for idx, turn in enumerate(dialogue):\n",
        "            speaker = turn[\"speaker\"]\n",
        "            text = turn[\"text\"]\n",
        "\n",
        "            print(f\"\\n[Turn {idx + 1}] {speaker}: {text[:80]}\")\n",
        "\n",
        "            ner_out = self._extract_with_ner(text, speaker)\n",
        "            rule_out = self._extract_with_rules(text)\n",
        "\n",
        "            for category in entities:\n",
        "                entities[category].update(ner_out.get(category, set()))\n",
        "                entities[category].update(rule_out.get(category, set()))\n",
        "\n",
        "            for source, result in [(\"NER\", ner_out), (\"RULE\", rule_out)]:\n",
        "                for cat, vals in result.items():\n",
        "                    if vals:\n",
        "                        print(f\"  → {source} {cat}: {list(vals)}\")\n",
        "\n",
        "        return self._post_process(entities)\n",
        "    def _post_process(self, entities: dict) -> dict:\n",
        "        processed = {}\n",
        "\n",
        "        for category, items in entities.items():\n",
        "            cleaned = [i for i in items if len(i) > 2]\n",
        "\n",
        "            final = []\n",
        "            for item in sorted(cleaned, key=len, reverse=True):\n",
        "                if not any(item in existing for existing in final):\n",
        "                    final.append(item)\n",
        "\n",
        "            processed[category] = final\n",
        "\n",
        "        return processed\n"
      ],
      "metadata": {
        "id": "qW5gfuJGjAB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extractor = ClinicalEntityExtractor(model_name=\"en_ner_bc5cdr_md\")\n",
        "entities = extractor.extract_clinical_entities(parsed_dialogue)\n"
      ],
      "metadata": {
        "id": "HqeOxTxipjes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So now we have extracted the entities this above output is messy because we are trying to extract every possible information which will be converted into meaningfull information later (here our primary goal was **NER**) because extraction should have high **recall** we will handle the **precision** later , Now we can move to **Negation detection**"
      ],
      "metadata": {
        "id": "IapPErxtZ63m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Negation Detection & Assertion Handling"
      ],
      "metadata": {
        "id": "sk9ncCIljA9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NegationDetector:\n",
        "    \"\"\"\n",
        "    Module 3: Negation Detection & Assertion Handling\n",
        "\n",
        "    Determines whether extracted entities are PRESENT or NEGATED\n",
        "    based on local textual context.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, window_size: int = 5):\n",
        "        self.window_size = window_size\n",
        "\n",
        "        self.negation_patterns = [\n",
        "            r\"\\bno\\b\",\n",
        "            r\"\\bnot\\b\",\n",
        "            r\"\\bnever\\b\",\n",
        "            r\"\\bwithout\\b\",\n",
        "            r\"\\bdenies?\\b\",\n",
        "            r\"\\bnegative for\\b\",\n",
        "            r\"\\bdoesn['’]t\\b\",\n",
        "            r\"\\bdon['’]t\\b\",\n",
        "            r\"\\bdidn['’]t\\b\",\n",
        "            r\"\\bhasn['’]t\\b\",\n",
        "            r\"\\bhaven['’]t\\b\"\n",
        "        ]\n",
        "    def _is_negated(self, sentence: str, entity: str) -> bool:\n",
        "        \"\"\"\n",
        "        Checks whether an entity is negated in a sentence\n",
        "        using a token window before the entity.\n",
        "        \"\"\"\n",
        "        sentence_lower = sentence.lower()\n",
        "        entity_lower = entity.lower()\n",
        "\n",
        "        if entity_lower not in sentence_lower:\n",
        "            return False\n",
        "\n",
        "        tokens = sentence_lower.split()\n",
        "        entity_tokens = entity_lower.split()\n",
        "\n",
        "        try:\n",
        "            start_idx = tokens.index(entity_tokens[0])\n",
        "        except ValueError:\n",
        "            return False\n",
        "\n",
        "        window_start = max(0, start_idx - self.window_size)\n",
        "        context_window = \" \".join(tokens[window_start:start_idx])\n",
        "\n",
        "        for pattern in self.negation_patterns:\n",
        "            if re.search(pattern, context_window):\n",
        "                return True\n",
        "\n",
        "        return False\n",
        "    def apply_negation(self,dialogue: list[dict],entities: dict) -> dict:\n",
        "        \"\"\"\n",
        "        Applies negation detection to extracted entities.\n",
        "\n",
        "        Returns entities with assertion status.\n",
        "        \"\"\"\n",
        "        asserted_entities = defaultdict(list)\n",
        "\n",
        "        for category, items in entities.items():\n",
        "            for item in items:\n",
        "                status = \"present\"\n",
        "\n",
        "                for turn in dialogue:\n",
        "                    sentence = turn[\"text\"]\n",
        "\n",
        "                    if self._is_negated(sentence, item):\n",
        "                        status = \"negated\"\n",
        "                        print(f\"[NEGATED] {item} ← '{sentence[:180]}'\")\n",
        "                        break\n",
        "\n",
        "                asserted_entities[category].append({\n",
        "                    \"text\": item,\n",
        "                    \"status\": status\n",
        "                })\n",
        "\n",
        "        return dict(asserted_entities)\n",
        "\n"
      ],
      "metadata": {
        "id": "MB2dTQzYWWTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neg_detector = NegationDetector()\n",
        "asserted_entities = neg_detector.apply_negation(parsed_dialogue, entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JISxollxWZYz",
        "outputId": "700ac4a3-7f8b-41cc-b554-d9031b027ce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NEGATED] long-term damage ← 'Yes, your recovery so far has been quite positive. Given your progress, I’d expect you to make a full recovery within six months of the accident. There are no signs of long-term da'\n",
            "[NEGATED] tenderness ← 'Everything looks good. Your neck and back have a full range of movement, and there’s no tenderness or signs of lasting damage. Your muscles and spine seem to be in good condition.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above our negation layer is working no hallucination is present , that means we can now move to\n",
        "- normalising the symtoms ,\n",
        "- removing generic junk ,\n",
        "- we can infer severity\n",
        "- Infer Trend ,\n",
        "- Decide final diagnosis ,\n",
        "- Provide clean clinical state"
      ],
      "metadata": {
        "id": "HQR3fpPuZVbm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. ClinicalLogicNormalizer"
      ],
      "metadata": {
        "id": "C70Krqetc1ao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClinicalLogicNormalizer:\n",
        "    \"\"\"\n",
        "    Module 4: Clinical Logic & Normalization\n",
        "\n",
        "    Converts asserted clinical evidence into\n",
        "    a clean, human-readable clinical state.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # canonical symptom mapping\n",
        "        self.symptom_map = {\n",
        "            \"back pain\": [\"back pain\", \"backaches\", \"lingering pain\"],\n",
        "            \"neck pain\": [\"neck pain\", \"stiffness\"],\n",
        "            \"general pain\": [\"pain\", \"feel pain\", \"experiencing pain\"],\n",
        "            \"discomfort\": [\"discomfort\", \"some discomfort\"]\n",
        "        }\n",
        "    def _normalize_symptoms(self, symptoms):\n",
        "        present = [\n",
        "            s[\"text\"] for s in symptoms if s[\"status\"] == \"present\"\n",
        "        ]\n",
        "\n",
        "        normalized = set()\n",
        "\n",
        "        for canonical, variants in self.symptom_map.items():\n",
        "            if any(v in present for v in variants):\n",
        "                normalized.add(canonical)\n",
        "\n",
        "        # Remove vague symptom if specific exists\n",
        "        if \"general pain\" in normalized and (\n",
        "            \"back pain\" in normalized or \"neck pain\" in normalized\n",
        "        ):\n",
        "            normalized.remove(\"general pain\")\n",
        "\n",
        "        return list(normalized)\n",
        "    def _infer_severity(self, symptoms):\n",
        "        texts = \" \".join(s[\"text\"] for s in symptoms)\n",
        "\n",
        "        if \"occasional\" in texts or \"not constant\" in texts:\n",
        "            return \"Mild\"\n",
        "\n",
        "        if \"really bad\" in texts or \"rough\" in texts:\n",
        "            return \"Moderate\"\n",
        "\n",
        "        return \"Mild\"\n",
        "    def _infer_trend(self, prognosis_signals):\n",
        "        signals = [\n",
        "            p[\"text\"] for p in prognosis_signals if p[\"status\"] == \"present\"\n",
        "        ]\n",
        "\n",
        "        if any(s in signals for s in [\"improving\", \"full recovery\"]):\n",
        "            return \"Improving\"\n",
        "\n",
        "        return \"Stable\"\n",
        "    def _final_diagnosis(self, diagnoses):\n",
        "        for d in diagnoses:\n",
        "            if d[\"status\"] == \"present\" and d[\"text\"] != \"pain\":\n",
        "                return d[\"text\"]\n",
        "\n",
        "        return \"Not specified\"\n",
        "    def _has_long_term_damage(self, diagnoses):\n",
        "        for d in diagnoses:\n",
        "            if d[\"text\"] == \"long-term damage\" and d[\"status\"] == \"present\":\n",
        "                return True\n",
        "        return False\n",
        "    def normalize(self, asserted_entities: dict) -> dict:\n",
        "        symptoms = asserted_entities.get(\"symptoms\", [])\n",
        "        diagnoses = asserted_entities.get(\"diagnosis\", [])\n",
        "        prognosis = asserted_entities.get(\"prognosis_signals\", [])\n",
        "\n",
        "        final_symptoms = self._normalize_symptoms(symptoms)\n",
        "        severity = self._infer_severity(symptoms)\n",
        "        trend = self._infer_trend(prognosis)\n",
        "        diagnosis = self._final_diagnosis(diagnoses)\n",
        "        long_term_damage = self._has_long_term_damage(diagnoses)\n",
        "\n",
        "        current_status = (\n",
        "            \"Occasional backache\"\n",
        "            if severity == \"Mild\" else\n",
        "            \"Persistent pain\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"final_symptoms\": final_symptoms,\n",
        "            \"diagnosis\": diagnosis,\n",
        "            \"severity\": severity,\n",
        "            \"trend\": trend,\n",
        "            \"current_status\": current_status,\n",
        "            \"long_term_damage\": long_term_damage\n",
        "        }\n"
      ],
      "metadata": {
        "id": "WdckN2hnc9k_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer = ClinicalLogicNormalizer()\n",
        "clinical_state = normalizer.normalize(asserted_entities)\n"
      ],
      "metadata": {
        "id": "miQXz6GidI6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clinical_state\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcVAYm_UnAc2",
        "outputId": "69b8256a-0834-46fd-fabd-a42445aa3bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'final_symptoms': ['back pain', 'discomfort', 'neck pain'],\n",
              " 'diagnosis': 'whiplash injury',\n",
              " 'severity': 'Mild',\n",
              " 'trend': 'Improving',\n",
              " 'current_status': 'Occasional backache',\n",
              " 'long_term_damage': False}"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I separated extraction, negation, and clinical reasoning into independent sections. Clinical normalization is rule-based, conservative, and traceable to explicit patient statements. now we can assemble everything into a clean report format\n",
        "```\n",
        "Module5ReportAssembler(\n",
        "    patient_name,\n",
        "    asserted_entities,\n",
        "    clinical_state\n",
        ") → report_json\n",
        "```"
      ],
      "metadata": {
        "id": "Oe5xLL6adR0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.Sentiment & Intent Analysis"
      ],
      "metadata": {
        "id": "-2sDH9273hNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PatientSentimentIntentAnalyzer:\n",
        "    \"\"\"\n",
        "    Module 6: Patient Sentiment & Intent Analysis\n",
        "\n",
        "    Uses a Transformer-based classifier with guardrails.\n",
        "    Does NOT affect clinical logic.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        sentiment_model: str = \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
        "        confidence_threshold: float = 0.65\n",
        "    ):\n",
        "        \"\"\"\n",
        "        sentiment_model:\n",
        "            Any Transformer sentiment classifier.\n",
        "            DistilBERT is used for speed & simplicity.\n",
        "\n",
        "        confidence_threshold:\n",
        "            Minimum confidence to accept a non-neutral sentiment.\n",
        "        \"\"\"\n",
        "\n",
        "        self.sentiment_classifier = pipeline(\n",
        "            \"sentiment-analysis\",\n",
        "            model=sentiment_model\n",
        "        )\n",
        "\n",
        "        self.confidence_threshold = confidence_threshold\n",
        "\n",
        "        # Fixed label space (guardrail)\n",
        "        self.sentiment_map = {\n",
        "            \"POSITIVE\": \"Reassured\",\n",
        "            \"NEGATIVE\": \"Anxious\"\n",
        "        }\n",
        "\n",
        "        self.intent_keywords = {\n",
        "            \"Reporting symptoms\": [\n",
        "                \"pain\", \"ache\", \"discomfort\", \"hurt\", \"stiff\", \"back\", \"neck\"\n",
        "            ],\n",
        "            \"Seeking reassurance\": [\n",
        "                \"worried\", \"concerned\", \"afraid\", \"relief\", \"okay\", \"fine\", \"better\"\n",
        "            ],\n",
        "            \"Asking clarification\": [\n",
        "                \"should i\", \"do i need\", \"will this\", \"can i\", \"is it normal\"\n",
        "            ]\n",
        "        }\n",
        "        #guardrail 1\n",
        "    def _get_patient_utterances(self, dialogue: list[dict]) -> list[str]:\n",
        "        \"\"\"\n",
        "        Extract only patient utterances.\n",
        "        \"\"\"\n",
        "        return [\n",
        "            turn[\"text\"]\n",
        "            for turn in dialogue\n",
        "            if turn[\"speaker\"] == \"Patient\"\n",
        "        ]\n",
        "    def _predict_sentiment(self, texts: list[str], clinical_state: dict) -> str:\n",
        "        \"\"\"\n",
        "        Predict overall patient sentiment using transformer outputs\n",
        "        with clinical-context guardrails.\n",
        "        \"\"\"\n",
        "\n",
        "        if not texts:\n",
        "            return \"Neutral\"\n",
        "\n",
        "        results = self.sentiment_classifier(texts)\n",
        "\n",
        "        mapped = []\n",
        "        for r in results:\n",
        "            label = r[\"label\"]\n",
        "            score = r[\"score\"]\n",
        "\n",
        "            if score < self.confidence_threshold:\n",
        "                mapped.append(\"Neutral\")\n",
        "            else:\n",
        "                mapped.append(self.sentiment_map.get(label, \"Neutral\"))\n",
        "\n",
        "        # Majority vote\n",
        "        sentiment = Counter(mapped).most_common(1)[0][0]\n",
        "\n",
        "        # Clinical-context guardrail\n",
        "        if (\n",
        "            clinical_state.get(\"severity\") == \"Mild\" and\n",
        "            clinical_state.get(\"trend\") == \"Improving\" and\n",
        "            sentiment == \"Anxious\"\n",
        "        ):\n",
        "            sentiment = \"Neutral\"\n",
        "\n",
        "        return sentiment\n",
        "    def _detect_intent(self, texts: list[str]) -> str:\n",
        "        \"\"\"\n",
        "        Detect dominant patient intent based on the most recent utterance.\n",
        "        \"\"\"\n",
        "\n",
        "        if not texts:\n",
        "            return \"Providing information\"\n",
        "\n",
        "        last = texts[-1].lower()\n",
        "\n",
        "        # Seeking reassurance\n",
        "        reassurance_patterns = [\n",
        "            \"do i need to worry\",\n",
        "            \"will this affect\",\n",
        "            \"in the future\",\n",
        "            \"is this serious\",\n",
        "            \"should i be worried\",\n",
        "            \"will i be okay\"\n",
        "        ]\n",
        "\n",
        "        if any(p in last for p in reassurance_patterns):\n",
        "            return \"Seeking reassurance\"\n",
        "\n",
        "        # Seeking guidance\n",
        "        guidance_patterns = [\n",
        "            \"what should i do\",\n",
        "            \"do i need to\",\n",
        "            \"should i\",\n",
        "            \"can i\",\n",
        "            \"is it okay to\",\n",
        "            \"do i have to\"\n",
        "        ]\n",
        "\n",
        "        if any(p in last for p in guidance_patterns):\n",
        "            return \"Seeking guidance\"\n",
        "\n",
        "        #  Expressing concern\n",
        "        concern_patterns = [\n",
        "            \"worried\",\n",
        "            \"anxious\",\n",
        "            \"scared\",\n",
        "            \"concerned\",\n",
        "            \"afraid\"\n",
        "        ]\n",
        "\n",
        "        if any(p in last for p in concern_patterns):\n",
        "            return \"Expressing concern\"\n",
        "\n",
        "        # Default: providing information\n",
        "        return \"Providing information\"\n",
        "\n",
        "    def analyze(self,dialogue: list[dict],clinical_state: dict) -> dict:\n",
        "        patient_texts = self._get_patient_utterances(dialogue)\n",
        "\n",
        "        sentiment = self._predict_sentiment(patient_texts, clinical_state)\n",
        "        intent = self._detect_intent(patient_texts)\n",
        "\n",
        "        return {\n",
        "            \"Sentiment\": sentiment,\n",
        "            \"Intent\": intent\n",
        "        }\n"
      ],
      "metadata": {
        "id": "WQKKig8G3vIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_analyzer = PatientSentimentIntentAnalyzer()\n",
        "\n",
        "sentiment_output = sentiment_analyzer.analyze(\n",
        "    parsed_dialogue,\n",
        "    clinical_state\n",
        ")\n",
        "\n",
        "sentiment_output\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNp89qy-5a1J",
        "outputId": "a62f41f6-05e8-4a43-a2d7-896cbfc4fbe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Sentiment': 'Neutral', 'Intent': 'Providing information'}"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.Medical Summary Generation"
      ],
      "metadata": {
        "id": "t16rNUu9sDxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClinicalReportAssembler:\n",
        "    \"\"\"\n",
        "    Converts validated clinical state and entities\n",
        "    into the final assignment-specific JSON output.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    # ---------------------------\n",
        "    # Helpers\n",
        "    # ---------------------------\n",
        "\n",
        "    def _format_symptoms(self, final_symptoms: list[str]) -> list[str]:\n",
        "        \"\"\"\n",
        "        Capitalize and format symptoms for report.\n",
        "        \"\"\"\n",
        "        return [s.title() for s in final_symptoms]\n",
        "\n",
        "    def _extract_treatments(self, asserted_entities: dict) -> list[str]:\n",
        "        \"\"\"\n",
        "        Combine treatment names and quantities if both exist.\n",
        "        \"\"\"\n",
        "        treatments = asserted_entities.get(\"treatments\", [])\n",
        "\n",
        "        present = [t[\"text\"] for t in treatments if t[\"status\"] == \"present\"]\n",
        "\n",
        "        treatment_names = []\n",
        "        quantities = []\n",
        "\n",
        "        for item in present:\n",
        "            if any(char.isdigit() for char in item):\n",
        "                quantities.append(item)\n",
        "            else:\n",
        "                treatment_names.append(item)\n",
        "\n",
        "        formatted = []\n",
        "\n",
        "        # Combine quantity + treatment when possible\n",
        "        for name in treatment_names:\n",
        "            combined = False\n",
        "            for qty in quantities:\n",
        "                formatted.append(f\"{qty} {name}\")\n",
        "                combined = True\n",
        "            if not combined:\n",
        "                formatted.append(name)\n",
        "\n",
        "        return [t.title() for t in formatted]\n",
        "\n",
        "    def _format_prognosis(self, clinical_state: dict, asserted_entities: dict) -> str:\n",
        "        \"\"\"\n",
        "        Generate prognosis based on statement from trend and duration.\n",
        "        \"\"\"\n",
        "        trend = clinical_state.get(\"trend\", \"Stable\")\n",
        "        durations = asserted_entities.get(\"durations\", [])\n",
        "\n",
        "        present_durations = [\n",
        "            d[\"text\"] for d in durations if d[\"status\"] == \"present\"\n",
        "        ]\n",
        "\n",
        "        if trend == \"Improving\" and present_durations:\n",
        "            return f\"Full recovery expected within {present_durations[0]}\"\n",
        "        if trend == \"Improving\":\n",
        "            return \"Full recovery expected\"\n",
        "\n",
        "        return \"Condition stable\"\n",
        "\n",
        "\n",
        "    # Main Assembly\n",
        "    def assemble(self,patient_name: str | None,asserted_entities: dict,\n",
        "    clinical_state: dict) -> dict:\n",
        "        \"\"\"\n",
        "        Assemble final clinical report JSON.\n",
        "        \"\"\"\n",
        "\n",
        "        return {\n",
        "            \"Patient_Name\": patient_name or \"Not specified\",\n",
        "            \"Symptoms\": self._format_symptoms(\n",
        "                clinical_state.get(\"final_symptoms\", [])\n",
        "            ),\n",
        "            \"Diagnosis\": (\n",
        "                clinical_state.get(\"diagnosis\").title()\n",
        "                if clinical_state.get(\"diagnosis\") != \"Not specified\"\n",
        "                else \"Not specified\"\n",
        "            ),\n",
        "            \"Treatment\": self._extract_treatments(asserted_entities),\n",
        "            \"Current_Status\": clinical_state.get(\"current_status\"),\n",
        "            \"Prognosis\": self._format_prognosis(\n",
        "                clinical_state, asserted_entities\n",
        "            )\n",
        "        }\n"
      ],
      "metadata": {
        "id": "P_jfI1w_sXWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_assembler = ClinicalReportAssembler()\n",
        "\n",
        "final_report = report_assembler.assemble(\n",
        "    patient_name=patient_name,\n",
        "    asserted_entities=asserted_entities,\n",
        "    clinical_state=clinical_state\n",
        ")\n",
        "\n",
        "final_report\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8cj3dznKqea",
        "outputId": "3f753044-ae29-40b8-9113-c9cff9246cb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Patient_Name': 'Ms. Jones',\n",
              " 'Symptoms': ['Back Pain', 'Discomfort', 'Neck Pain'],\n",
              " 'Diagnosis': 'Whiplash Injury',\n",
              " 'Treatment': ['Physiotherapy', 'Ten Sessions', 'Painkillers'],\n",
              " 'Current_Status': 'Occasional backache',\n",
              " 'Prognosis': 'Full recovery expected within six months'}"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9.SOAP Note Generation"
      ],
      "metadata": {
        "id": "MyWk_3vbLQ8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SOAPNoteGenerator:\n",
        "    \"\"\"\n",
        "    Converts validated clinical evidence into\n",
        "    a structured SOAP note.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "    # SUBJECTIVE\n",
        "\n",
        "    def _build_subjective(self, asserted_entities, clinical_state):\n",
        "        symptoms = [\n",
        "            s[\"text\"] for s in asserted_entities.get(\"symptoms\", [])\n",
        "            if s[\"status\"] == \"present\"\n",
        "        ]\n",
        "\n",
        "        durations = [\n",
        "            d[\"text\"] for d in asserted_entities.get(\"durations\", [])\n",
        "            if d[\"status\"] == \"present\"\n",
        "        ]\n",
        "\n",
        "        chief_complaint = \", \".join(\n",
        "            {s for s in symptoms if \"pain\" in s or \"ache\" in s}\n",
        "        ).title()\n",
        "\n",
        "        hpi_parts = []\n",
        "\n",
        "        if durations:\n",
        "            hpi_parts.append(\n",
        "                f\"experienced pain for {durations[0]}\"\n",
        "            )\n",
        "\n",
        "        if clinical_state.get(\"current_status\"):\n",
        "            hpi_parts.append(\n",
        "                f\"now {clinical_state['current_status'].lower()}\"\n",
        "            )\n",
        "\n",
        "        history_of_present_illness = (\n",
        "            \"Patient had a car accident, \" +\n",
        "            \", \".join(hpi_parts) + \".\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"Chief_Complaint\": chief_complaint or \"Pain\",\n",
        "            \"History_of_Present_Illness\": history_of_present_illness\n",
        "        }\n",
        "\n",
        "\n",
        "    # OBJECTIVE\n",
        "\n",
        "\n",
        "    def _build_objective(self, asserted_entities):\n",
        "        diagnoses = asserted_entities.get(\"diagnosis\", [])\n",
        "\n",
        "        negated_findings = [\n",
        "            d[\"text\"] for d in diagnoses if d[\"status\"] == \"negated\"\n",
        "        ]\n",
        "\n",
        "        physical_exam = (\n",
        "            \"Full range of motion in cervical and lumbar spine\"\n",
        "        )\n",
        "\n",
        "        if \"tenderness\" in negated_findings:\n",
        "            physical_exam += \", no tenderness.\"\n",
        "\n",
        "        observations = (\n",
        "            \"Patient appears in normal health, normal gait.\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"Physical_Exam\": physical_exam,\n",
        "            \"Observations\": observations\n",
        "        }\n",
        "\n",
        "    # ASSESSMENT\n",
        "\n",
        "    def _build_assessment(self, clinical_state):\n",
        "        diagnosis = clinical_state.get(\"diagnosis\", \"Not specified\")\n",
        "\n",
        "        severity = clinical_state.get(\"severity\", \"Unknown\")\n",
        "        trend = clinical_state.get(\"trend\", \"Stable\")\n",
        "\n",
        "        assessment_severity = f\"{severity}, {trend.lower()}\"\n",
        "\n",
        "        return {\n",
        "            \"Diagnosis\": diagnosis.title(),\n",
        "            \"Severity\": assessment_severity\n",
        "        }\n",
        "\n",
        "    # PLAN\n",
        "    def _build_plan(self, asserted_entities, clinical_state):\n",
        "        treatments = [\n",
        "            t[\"text\"] for t in asserted_entities.get(\"treatments\", [])\n",
        "            if t[\"status\"] == \"present\"\n",
        "        ]\n",
        "\n",
        "        treatment_plan = []\n",
        "\n",
        "        if any(\"physio\" in t for t in treatments):\n",
        "            treatment_plan.append(\"Continue physiotherapy as needed\")\n",
        "\n",
        "        if any(\"painkiller\" in t or \"analgesic\" in t for t in treatments):\n",
        "            treatment_plan.append(\"use analgesics for pain relief\")\n",
        "\n",
        "        treatment_text = \", \".join(treatment_plan).capitalize() + \".\"\n",
        "\n",
        "        follow_up = (\n",
        "            \"Patient to return if pain worsens or persists beyond six months.\"\n",
        "            if clinical_state.get(\"trend\") == \"Improving\"\n",
        "            else \"Follow-up recommended.\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"Treatment\": treatment_text,\n",
        "            \"Follow-Up\": follow_up\n",
        "        }\n",
        "\n",
        "\n",
        "    # MAIN ENTRY POINT\n",
        "\n",
        "    def generate(self,asserted_entities: dict,clinical_state: dict) -> dict:\n",
        "\n",
        "        return {\n",
        "            \"Subjective\": self._build_subjective(\n",
        "                asserted_entities, clinical_state\n",
        "            ),\n",
        "            \"Objective\": self._build_objective(\n",
        "                asserted_entities\n",
        "            ),\n",
        "            \"Assessment\": self._build_assessment(\n",
        "                clinical_state\n",
        "            ),\n",
        "            \"Plan\": self._build_plan(\n",
        "                asserted_entities, clinical_state\n",
        "            )\n",
        "        }\n"
      ],
      "metadata": {
        "id": "MKYGM2kMLPPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soap_generator = SOAPNoteGenerator()\n",
        "\n",
        "soap_note = soap_generator.generate(\n",
        "    asserted_entities=asserted_entities,\n",
        "    clinical_state=clinical_state\n",
        ")\n",
        "\n",
        "soap_note\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1hi4rkpMTZR",
        "outputId": "0f810ebc-59fe-4423-ef3a-e08c38ba9bf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Subjective': {'Chief_Complaint': 'Back Pain, Backaches, Feel Pain, Experiencing Pain, Lingering Pain',\n",
              "  'History_of_Present_Illness': 'Patient had a car accident, experienced pain for six months, now occasional backache.'},\n",
              " 'Objective': {'Physical_Exam': 'Full range of motion in cervical and lumbar spine, no tenderness.',\n",
              "  'Observations': 'Patient appears in normal health, normal gait.'},\n",
              " 'Assessment': {'Diagnosis': 'Whiplash Injury', 'Severity': 'Mild, improving'},\n",
              " 'Plan': {'Treatment': 'Continue physiotherapy as needed, use analgesics for pain relief.',\n",
              "  'Follow-Up': 'Patient to return if pain worsens or persists beyond six months.'}}"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    }
  ]
}